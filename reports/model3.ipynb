{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report 3\n",
    "\n",
    "This is the report for the LeNet-5 Network I implemented. I did the same preprocesing steps I mentioned in Report 1, as well as another one: the random transformation of images. Since some classes were still very underrepresented after doing the preprocessing steps I mentioned, I also did another step: The random transformation of an image into a fairly similar image. The image retains it recognaizability, but is different to the original.\n",
    "\n",
    "Here an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage.transform import rotate, warp, ProjectiveTransform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#prepare parameters for randomization\n",
    "image_path = ('../images/train/00hc.ppm')\n",
    "intensity = 0.75\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "resize = cv2.resize(img, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "image_shape = resize.shape\n",
    "image_size = image_shape[0]\n",
    "d = image_size * 0.3 * intensity\n",
    "#With these 8 parameters we can perform a transofrmation of the image in such a way\n",
    "#that the image is different enough from the original but not too different, since\n",
    "#we should be able to still recognize the class in the transformed image.\n",
    "tl_top = random.uniform(-d, d)     # Top left corner, top margin\n",
    "tl_left = random.uniform(-d, d)    # Top left corner, left margin\n",
    "bl_bottom = random.uniform(-d, d)  # Bottom left corner, bottom margin\n",
    "bl_left = random.uniform(-d, d)    # Bottom left corner, left margin\n",
    "tr_top = random.uniform(-d, d)     # Top right corner, top margin\n",
    "tr_right = random.uniform(-d, d)   # Top right corner, right margin\n",
    "br_bottom = random.uniform(-d, d)  # Bottom right corner, bottom margin\n",
    "br_right = random.uniform(-d, d)   # Bottom right corner, right margin\n",
    "transform = ProjectiveTransform()\n",
    "transform.estimate(np.array((\n",
    "           (tl_left, tl_top),\n",
    "           (bl_left, image_size - bl_bottom),\n",
    "           (image_size - br_right, image_size - br_bottom),\n",
    "           (image_size - tr_right, tr_top)\n",
    "       )), np.array((\n",
    "           (0, 0),\n",
    "           (0, image_size),\n",
    "           (image_size, image_size),\n",
    "           (image_size, 0)\n",
    "       )))\n",
    "warped = warp(resize,\n",
    "           transform, output_shape=(image_size, image_size), order = 1, mode = 'edge')\n",
    "fig = plt.figure(figsize=(2, 1))\n",
    "axis = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
    "axis.imshow(resize)\n",
    "axis = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])\n",
    "axis.imshow(warped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in the left is the original and in the right the transformed image. The image mantains its properties (i.e. we can easily recognize its the same class) but is different. \n",
    "\n",
    "Now lets see how my implementation of LeNet fares against this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meyer/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/model3/saved/lenet\n",
      "Test Accuracy = 0.840\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def tanh_lecun(x):\n",
    "    \"\"\"\n",
    "    The special hyperbolic tangent function proposed by LeCun.\n",
    "    Built with Tensorflow primitives so that tensorflow can use it easily and propagate\n",
    "    and compute the gradients appropiately.\n",
    "    The function is f(a) = A*tanh(S*a), with S and A specified below.\n",
    "    \"\"\"\n",
    "    A = tf.constant(1.17159)\n",
    "    S = tf.constant(2.0/3.0)\n",
    "    mult = tf.multiply(S, x)\n",
    "    app = tf.nn.tanh(mult)\n",
    "    return tf.multiply(A, app)\n",
    "\n",
    "def lenet(x):\n",
    "    #Parameters for randomly initliasing the different weight values.\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    #I'm gonna initialize all weights with mean 0 and 0.1 standard deviation.\n",
    "    #The weight initliazition procedure proposed in LeCun gives extremely high values and\n",
    "    #the network becomes inefficient. Maybe it is a good intilization for the digit recognition\n",
    "    #problem but not for this problem?\n",
    "    #This is the first convolutional layer C1\n",
    "    #Initialize weights for the first convolutional layer. 6 feature maps connected to\n",
    "    #one (1) 5x5 neighborhood in the input. 5*5*1*6=150 trainable parameters\n",
    "    C1_w = tf.Variable(tf.truncated_normal(shape = [5,5,1,6], mean=mu, stddev=sigma))\n",
    "    #Bias for each feature map. 6 parameters, with the weights we have 156 parameters\n",
    "    C1_b = tf.Variable(tf.zeros(6))\n",
    "    #Define the convolution layer with the weights and biases defined.\n",
    "    C1 = tf.nn.conv2d(x, C1_w, strides = [1,1,1,1], padding = 'VALID') + C1_b\n",
    "    #LeCun uses a sigmoidal activation function here.\n",
    "    C1 = tanh_lecun(C1)\n",
    "\n",
    "    #This is the sub-sampling layer S2\n",
    "    #Subsampling (also known as average pooling) with 2x2 receptive fields. 12 parameters.\n",
    "    S2 = tf.nn.avg_pool(C1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    #The result is passed to a sigmoidal function\n",
    "    S2 = tanh_lecun(S2)\n",
    "\n",
    "    #Another convolutional layer C3.\n",
    "    #Initlialize weights. 16 feature maps connected connected to 5*5 neighborhoods\n",
    "    #5*5*6*16=2400+16=2416 trainable parameters. Little difference with LeCun here as they\n",
    "    #have less parameters to train in this part.\n",
    "    C3_w = tf.Variable(tf.truncated_normal(shape = [5,5,6,16], mean=mu, stddev=sigma))\n",
    "    #not all feature maps are used, need to split\n",
    "    C3_b = tf.Variable(tf.zeros(16))\n",
    "    C3 = tf.nn.conv2d(S2, C3_w, strides = [1,1,1,1], padding = 'VALID') + C3_b\n",
    "    C3 = tanh_lecun(C3)\n",
    "\n",
    "    #Sub-sampling layer S2\n",
    "    S4 = tf.nn.avg_pool(C3, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    #Activation\n",
    "    S4 = tanh_lecun(S4)\n",
    "\n",
    "    #C5: Flattened with 120 feature maps. Full connection. Labeled as convolutional\n",
    "    #insted of fully-connected because if LeNet-5 input were made bigger with\n",
    "    #everything else kept constat the feature map dimension would be larger than 1x1.\n",
    "    #Shape = 400 since each unit is connected to 5x5 neighbors on the 16 features maps\n",
    "    #of S4.\n",
    "    C5 = flatten(S4)\n",
    "    C5_w = tf.Variable(tf.truncated_normal(shape = (400,120), mean=mu, stddev=sigma))\n",
    "    C5_b = tf.Variable(tf.zeros(120))\n",
    "    C5 = tf.matmul(C5,C5_w) + C5_b\n",
    "    #Activation\n",
    "    C5 = tanh_lecun(C5)\n",
    "\n",
    "    #Fully connected with 84 units. Has 10164 trainable parameters 120*84 + 84 = 10164\n",
    "    F6_w = tf.Variable(tf.truncated_normal(shape = (120,84), mean=mu, stddev=sigma))\n",
    "    F6_b = tf.Variable(tf.zeros(84))\n",
    "    F6 = tf.matmul(C5,F6_w) + F6_b\n",
    "    # Activation\n",
    "    F6 = tanh_lecun(F6)\n",
    "\n",
    "    # Output Layer: shape 84x43 (84 from the last layer, 43 because that is the number of\n",
    "    # classes in our classification problem).\n",
    "    out_w = tf.Variable(tf.truncated_normal(shape = (84,43), mean=mu, stddev=sigma))\n",
    "    out_b = tf.Variable(tf.zeros(43))\n",
    "    out = tf.matmul(F6, out_w) + out_b\n",
    "    return out\n",
    "\n",
    "def create_input(path):\n",
    "    \"\"\"\n",
    "    Create Lenet's input with appropiate structure given a path (e.g. './images/train' or\n",
    "    './images/test')\n",
    "    \"\"\"\n",
    "    folder =  path\n",
    "    files = os.listdir(folder)\n",
    "    x = []\n",
    "    y = []\n",
    "    image_paths = []\n",
    "    scaler = MinMaxScaler(feature_range=(-0.1, 1.175))\n",
    "    #noramlized as in LeCun, makes the mean input roughly 0 and the variance roughly 1.\n",
    "    #This accelerates learning.\n",
    "    for i, images in sorted(enumerate(files)):\n",
    "        label = images[0:2] #class identifier is in these positions\n",
    "        image_path = folder + '/' + images\n",
    "        image_paths.append(image_path)\n",
    "        image_read = cv2.imread(image_path, 0)\n",
    "        resize = cv2.resize(image_read, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        X_new = scaler.fit_transform(resize)\n",
    "        x.append(X_new)\n",
    "        y.append(int(label))\n",
    "    X = np.array(x)\n",
    "    n, m, p = X.shape\n",
    "    x_aux = []\n",
    "    for example in X:\n",
    "        for row in example:\n",
    "            for element in row:\n",
    "                x_aux.append([element])\n",
    "    x_aux = np.array(x_aux)\n",
    "    x_aux = np.reshape(x_aux, (n, 32, 32, 1))\n",
    "    return x_aux, y, image_paths\n",
    "\n",
    "d = '../images/test'\n",
    "X_test, y_test, _ = create_input(d)\n",
    "BATCH_SIZE = 1\n",
    "#auxiliary\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43) #Diagonal 43x43 Identity Matrix\n",
    "#Initialize\n",
    "out = lenet(x)\n",
    "\n",
    "#see if the prediction is correct, create an accuracy operation\n",
    "correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data, batch_size):\n",
    "    \"\"\"\n",
    "    Evaluate how well the models does on the training set.\n",
    "    \"\"\"\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset+batch_size],y_data[offset:offset+batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples, total_accuracy\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Initialize\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    #Restore saved model\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('../models/model3/saved/'))\n",
    "\n",
    "    #Evaluate\n",
    "    test_accuracy, total_accuracy = evaluate(X_test, y_test, BATCH_SIZE)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have an accuracy of 84%. That is pretty good for a database with such few images! Deep neural networks are so much better at classifying than linear models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
